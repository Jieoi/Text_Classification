{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04aefc8d",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <b><h1> Couserwork Assignment: Text Classification</h1></b>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d3c79a",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h3>University of London</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4850a4fc",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h3>BSc in Computer Science</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c3cb96",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h3>Natural Language Processing</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fbe0bc",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36069138",
   "metadata": {},
   "source": [
    "<h1> Table of Content</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0acbe",
   "metadata": {},
   "source": [
    "<style>\n",
    "ul {\n",
    "    font-size: 20px;\n",
    "}\n",
    "\n",
    "ul ul {\n",
    "    font-size: 15px;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        <a href=\"#intro\">1. Introduction</a>\n",
    "        <ul>\n",
    "            <li><a href=\"#1.1\">1.1 Problem Area</a></li>\n",
    "            <li><a href=\"#1.2\">1.2 Objectives</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#section2\">Section 2</a>\n",
    "        <ul>\n",
    "            <li><a href=\"#subsection2.1\">Subsection 2.1</a></li>\n",
    "            <li><a href=\"#subsection2.2\">Subsection 2.2</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#section3\">Section 3</a>\n",
    "        <ul>\n",
    "            <li><a href=\"#subsection3.1\">Subsection 3.1</a></li>\n",
    "            <li><a href=\"#subsection3.2\">Subsection 3.2</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f79f63",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b291f5f6",
   "metadata": {},
   "source": [
    "<h2 id=\"intro\">1. Introduction</h2>\n",
    "<h3 id=\"1.1\">1.1 Problem area</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464044f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5846b2d",
   "metadata": {},
   "source": [
    "<h3 id=\"\">Data Extraction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660ef232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library needed for data analysis\n",
    "import os\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6e8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folders\n",
    "pos_folder = r'C:\\Users\\xjie\\Documents\\SIM\\Y3S2\\nlp\\aclImdb\\train\\pos'\n",
    "neg_folder = r'C:\\Users\\xjie\\Documents\\SIM\\Y3S2\\nlp\\aclImdb\\train\\neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a8a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions;\n",
    "\n",
    "# Count the number of files in the data folder\n",
    "def count_files(folder_path):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Error: {folder_path} is not a valid directory.\")\n",
    "        return\n",
    "\n",
    "    file_count = 0\n",
    "\n",
    "    for _, _, files in os.walk(folder_path):\n",
    "        file_count += len(files)\n",
    "\n",
    "    return file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f13f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of files in positive training folder is: 12500\n"
     ]
    }
   ],
   "source": [
    "# Example the positive training data file\n",
    "file_count = count_files(pos_folder)\n",
    "print(f\"The number of files in positive training folder is: {file_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d30de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of files in positive training folder is: 12500\n"
     ]
    }
   ],
   "source": [
    "# Example the positive training data file\n",
    "file_count = count_files(pos_folder)\n",
    "print(f\"The number of files in positive training folder is: {file_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ac5c6",
   "metadata": {},
   "source": [
    "As the training data set is <b>too big</b> for the computer, only <b>2000 data</b> from positive and negative folder will be selected to make the program runs faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e9fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# Function to extract unique ID and rating from file name\n",
    "def extract_info(file_name):\n",
    "    id_rating = file_name.split('.')[0]\n",
    "    unique_id, rating = id_rating.split('_')\n",
    "    return int(unique_id), int(rating)\n",
    "\n",
    "# Function to extract the data from the file based on the aclImdb data structure\n",
    "def extract_files(folder, num_files, sentiment):\n",
    "    files = random.sample(os.listdir(folder), num_files)\n",
    "    data = pd.DataFrame(columns=['Sentiment', 'Unique ID', 'Rating', 'Content'])\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read() # read content for the review\n",
    "        unique_id, rating = extract_info(file_name)  # get ID and rating from file name\n",
    "        file_data = pd.DataFrame({'Sentiment': [sentiment], 'Unique ID': [unique_id], 'Rating': [rating], 'Content': [content]})\n",
    "        data = pd.concat([data, file_data], ignore_index=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d91458ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>9724</td>\n",
       "      <td>7</td>\n",
       "      <td>I love Kristen Dunst, especially in Elizabetht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>7401</td>\n",
       "      <td>9</td>\n",
       "      <td>I found it highly interesting that the film ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>5422</td>\n",
       "      <td>9</td>\n",
       "      <td>The story of the untouchable who acted like a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>5473</td>\n",
       "      <td>8</td>\n",
       "      <td>This one is considered a key Pre-Code film  f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>7170</td>\n",
       "      <td>9</td>\n",
       "      <td>HOLES is not your average Disney stuff- it's v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment Unique ID Rating   \n",
       "0       pos      9724      7  \\\n",
       "1       pos      7401      9   \n",
       "2       pos      5422      9   \n",
       "3       pos      5473      8   \n",
       "4       pos      7170      9   \n",
       "\n",
       "                                             Content  \n",
       "0  I love Kristen Dunst, especially in Elizabetht...  \n",
       "1  I found it highly interesting that the film ac...  \n",
       "2  The story of the untouchable who acted like a ...  \n",
       "3  This one is considered a key Pre-Code film  f...  \n",
       "4  HOLES is not your average Disney stuff- it's v...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting training data\n",
    "pos_data = extract_files(pos_folder, 2000, 'pos')\n",
    "neg_data = extract_files(neg_folder, 2000, 'neg')\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "raw_data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "\n",
    "# Display the start of the data\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f51fc5",
   "metadata": {},
   "source": [
    "<h3 id=\"\">Prelimary analysis and data cleaning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c4edab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>3684</td>\n",
       "      <td>8</td>\n",
       "      <td>3998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>pos</td>\n",
       "      <td>9428</td>\n",
       "      <td>1</td>\n",
       "      <td>This film was so amateurish I could hardly bel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>806</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentiment  Unique ID  Rating   \n",
       "count       4000       4000    4000  \\\n",
       "unique         2       3684       8   \n",
       "top          pos       9428       1   \n",
       "freq        2000          2     806   \n",
       "\n",
       "                                                  Content  \n",
       "count                                                4000  \n",
       "unique                                               3998  \n",
       "top     This film was so amateurish I could hardly bel...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examining the data\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21debea9",
   "metadata": {},
   "source": [
    "It was noted that both Unique ID and Content has duplicated values. Thus, an algorithm will be implemented to check for these values and handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bafd4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "# Check for repetetion of data\n",
    "def find_duplicates(dataframe, column):\n",
    "    duplicates = dataframe[dataframe[column].duplicated(keep=False)]\n",
    "    duplicates_sorted = duplicates.sort_values(by=column)\n",
    "\n",
    "    if duplicates_sorted.empty:\n",
    "        print(\"No repeated data entry found.\")\n",
    "    else:\n",
    "        print(\"Repeated data entry/entries found in \"+str(column))\n",
    "        duplicates_pairs = duplicates_sorted.groupby(column).apply(lambda x: x.reset_index(drop=True))\n",
    "        duplicates_pairs.reset_index(drop=True, inplace=True)\n",
    "        return duplicates_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f03f7919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated data entry/entries found in Content\n",
      "Repeated data entry/entries found in Unique ID\n",
      "--------------------------------------------------\n",
      "Duplication in content:\n",
      "  Sentiment Unique ID Rating   \n",
      "0       neg      7091      1  \\\n",
      "1       neg      7086      1   \n",
      "2       neg       282      1   \n",
      "3       neg     10333      1   \n",
      "\n",
      "                                             Content  \n",
      "0  This film was so amateurish I could hardly bel...  \n",
      "1  This film was so amateurish I could hardly bel...  \n",
      "2  What was an exciting and fairly original serie...  \n",
      "3  What was an exciting and fairly original serie...  \n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Duplication in ID:\n",
      "    Sentiment Unique ID Rating   \n",
      "0         pos         6     10  \\\n",
      "1         neg         6      1   \n",
      "2         pos         8      7   \n",
      "3         neg         8      4   \n",
      "4         pos        10      9   \n",
      "..        ...       ...    ...   \n",
      "627       neg     12385      1   \n",
      "628       pos     12387     10   \n",
      "629       neg     12387      4   \n",
      "630       pos     12486      7   \n",
      "631       neg     12486      2   \n",
      "\n",
      "                                               Content  \n",
      "0    Fair drama/love story movie that focuses on th...  \n",
      "1    From the beginning of the movie, it gives the ...  \n",
      "2    Very good drama although it appeared to have a...  \n",
      "3    6/10 Acting, not great but some good acting.<b...  \n",
      "4    I'm a male, not given to women's movies, but t...  \n",
      "..                                                 ...  \n",
      "627  This film is so ridiculously idiot that you ma...  \n",
      "628  Of all the movies of the seventies, none captu...  \n",
      "629  Lipstick is another glossy movie failure.I am ...  \n",
      "630  Well, this film is a difficult one really. To ...  \n",
      "631  Rich ditzy Joan Winfield (a woefully miscast B...  \n",
      "\n",
      "[632 rows x 4 columns]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "duplicate_content = find_duplicates(raw_data, 'Content')\n",
    "duplicate_ID = find_duplicates(raw_data, 'Unique ID')\n",
    "\n",
    "if duplicate_content is not None:\n",
    "    print('-' * 50)\n",
    "    print(\"Duplication in content:\")\n",
    "    print(duplicate_content)\n",
    "    print('-' * 50)\n",
    "if duplicate_ID is not None:\n",
    "    print('-' * 50)\n",
    "    print(\"Duplication in ID:\")\n",
    "    print(duplicate_ID)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c8773",
   "metadata": {},
   "source": [
    "As a <b>new ID is assigned</b> as the index for the data frame, there is <b>no need</b> for the Unique ID from positive sentiment and negative sentiment folder. Thus, the <b>unique ID column will be dropped</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d158ec5",
   "metadata": {},
   "source": [
    "Moreover, the duplicated content will be <b>remove<b/> and new data will be loaded to replace them so that the dataset remains balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbbb8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unique ID column from the data\n",
    "org_ID_removed_data = raw_data.drop(\"Unique ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8e266cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace duplicates with other values\n",
    "def get_balance_data_with_duplicates(duplicate_content, original_data, pos_folder, neg_folder):\n",
    "    # Remove the first occurrence of unique items in the duplicated content\n",
    "    data_to_remove = duplicate_content.drop_duplicates(subset='Content', keep='first')\n",
    "    org_ID_removed_data = original_data.drop_duplicates(subset='Content', keep='first')\n",
    "\n",
    "    # Count the number of pos and neg entries in 'data_to_remove'\n",
    "    pos_count = data_to_remove[data_to_remove['Sentiment'] == 'pos'].shape[0]\n",
    "    neg_count = data_to_remove[data_to_remove['Sentiment'] == 'neg'].shape[0]\n",
    "\n",
    "    # Add the removed duplicates such that the data is balanced\n",
    "    added_pos_data = extract_files(pos_folder, pos_count, 'pos')\n",
    "    added_neg_data = extract_files(neg_folder, neg_count, 'neg')\n",
    "\n",
    "    # Remove the 'Unique ID' column from added data\n",
    "    added_pos_data.drop(\"Unique ID\", axis=1, inplace=True)\n",
    "    added_neg_data.drop(\"Unique ID\", axis=1, inplace=True)\n",
    "\n",
    "    added_data = pd.concat([added_pos_data, added_neg_data], ignore_index=True)\n",
    "    balanced_data = pd.concat([org_ID_removed_data, added_data], ignore_index=True)\n",
    "\n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f202abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_data_balancing(dataframe, column, pos_folder, neg_folder):\n",
    "    duplicates = find_duplicates(dataframe, column)\n",
    "\n",
    "    if duplicates is None:\n",
    "        print(\"No more duplicates found.\")\n",
    "        return dataframe\n",
    "\n",
    "    # Call get_balance_data_with_duplicates with the duplicate content\n",
    "    balanced_data = get_balance_data_with_duplicates(duplicates, dataframe, pos_folder, neg_folder)\n",
    "\n",
    "    # Recursively check for duplicates\n",
    "    print(\"Recursive call to balance the data.\")\n",
    "    return recursive_data_balancing(balanced_data, column, pos_folder, neg_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "389b4ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated data entry/entries found in Content\n",
      "Recursive call to balance the data.\n",
      "No repeated data entry found.\n",
      "No more duplicates found.\n"
     ]
    }
   ],
   "source": [
    "balanced_data = recursive_data_balancing(org_ID_removed_data, 'Content', pos_folder, neg_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25248cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48da5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double checking the total number of data entries\n",
    "data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb8e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
