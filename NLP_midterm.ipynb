{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04aefc8d",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <b><h1> Couserwork Assignment: Text Classification</h1></b>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d3c79a",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h3>University of London</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4850a4fc",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h3>BSc in Computer Science</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c3cb96",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h3>Natural Language Processing</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fbe0bc",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36069138",
   "metadata": {},
   "source": [
    "<h1> Table of Content</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0acbe",
   "metadata": {},
   "source": [
    "<style>\n",
    "ul {\n",
    "    font-size: 20px;\n",
    "}\n",
    "\n",
    "ul ul {\n",
    "    font-size: 15px;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        <a href=\"#intro\">1. Introduction</a>\n",
    "        <ul>\n",
    "            <li><a href=\"#1.1\">1.1 Problem Area</a></li>\n",
    "            <li><a href=\"#1.2\">1.2 Objectives</a></li>\n",
    "            <li><a href=\"#1.3\">1.3 Choice of Dataset</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#implementation\">2. Implementation</a>\n",
    "        <ul>\n",
    "            <li><a href=\"#2.1\">2.1 Processing</a></li>\n",
    "            <ul>\n",
    "                <li><a href=\"#2.1.1\">2.1.1 Data Extraction and Cleaning</a></li>\n",
    "                <li><a href=\"#2.1.2\">2.1.2 Prelimary Data Exploration and Data Cleaning</a></li>\n",
    "                <li><a href=\"#2.1.3\">2.1.3 Vocabulary statistic</a></li>\n",
    "            </ul>\n",
    "            <li><a href=\"#2.2\">2.2 Baseline performance</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Conc\">3. Conclusion</a>\n",
    "        <ul>\n",
    "            <li><a href=\"#3.1\">3.1 Evaluation</a></li>\n",
    "            <li><a href=\"#3.2\">3.2 Project Evaluation and Summary</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f79f63",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b291f5f6",
   "metadata": {},
   "source": [
    "<h2 id=\"intro\">1. Introduction</h2>\n",
    "<h3 id=\"1.1\">1.1 Problem area</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d49b50",
   "metadata": {},
   "source": [
    "Our current generation has witnessed unprecedented global growth, be it in the economy or technology sectors. However, since the late 2010s, the landscape has undergone significant transformations. The conflicts around the world, deceleration in multiple sectors, and rise of protectionism have posed challenges to the old strategy of relying solely on continuous economic expansion. This challenge is fuelled by the unfavorable economic outlook observed since the 2020s. As a result, individuals have become more conservative and cautious in their spending habits. Consequently, businesses across sectors must vigilantly monitor shifts in consumer sentiment. By extracting insights from sentiment analysis, companies can understand consumer attitudes toward their products and services, as well as their overall brand image. This knowledge enables companies to promptly adapt and implement new strategies, ensuring their relevance in this volatile economic environment.\n",
    "\n",
    "The film industry has been severely impacted by declining attendance, attributed to both slowing economic growth and a lack of compelling content. (sg) The coronavirus pandemic has further exacerbated the situation with lockdowns and admission restrictions. (us) Movie theaters now face fierce competition from alternative entertainment sources, especially video games, which experienced an impressive 20% growth in 2020. (us) To ensure continued prosperity, industry decision-makers must promptly reassess their strategies, giving paramount importance to audience opinions and feedback. Sentiment analysis becomes a critical tool for understanding audience preferences and sentiments, enabling the film industry to adapt and thrive in an ever-evolving entertainment landscape.\n",
    "\n",
    "Despite the prevailing economic challenges, the film industry achieved a remarkable milestone in 2019, surpassing the $101 billion USD mark. This multi-billion-dollar industry still holds significant potential for prosperity. While attracting new consumers to choose movies as their primary source of entertainment may present difficulties, companies can focus on retaining their existing viewer base. Leveraging sentiment analysis, specifically tailored to movie reviews, becomes essential as it provides valuable insights into viewers' preferences and dislikes. By incorporating these insights, future movie productions can effectively cater to the preferences of the target audience, fostering continued success in the industry.\n",
    "\n",
    "Factually speaking, the internet has become a vast database of opinions created by consumers. They express their thoughts through various channels such as Twitter, Facebook, IMDB, and Rotten Tomatoes. The model developed for sentimental analysis for the film industry can be transferred to and utilized in other sectors of the economy.  With appropriate refinement, this model has the potential to provide valuable insights into user sentiments in domains that may not have direct connections to the film industry. This demonstrates the versatility and applicability of sentiment analysis beyond its initial scope, offering a valuable tool for understanding consumer sentiment in diverse fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab5cfbb",
   "metadata": {},
   "source": [
    "Word Count:436"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50738505",
   "metadata": {},
   "source": [
    "<h3 id=\"1.2\">1.2 Objective</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a7ac2c",
   "metadata": {},
   "source": [
    "The <b>objective</b> of this research is to conduct sentiment analysis on movie reviews utilizing text classification models. The project's focus will be on implementing and comparing the effectiveness of different classification algorithms. \n",
    "\n",
    "The <b>aim</b> of this project will be categorizing users' movie reviews into binary classes of positive or negative sentiments. \n",
    "\n",
    "This research aims to contribute to the field of sentiment analysis by adding to the knowledge of users' sentiment towards movies and using this knowledge to provide valuable insights for the film industry.\n",
    "\n",
    "While it is true that there have been many researches conducted on sentiment analysis and its application in the film industry, this particular research still holds its value and relevance. Granted that this is not groundbreaking research in this sector, it still <b>contributes to the existing body of knowledge</b> and <b>provides more insights</b>, and has the potential to be applied elsewhere. \n",
    "\n",
    "The insights are essential to <b>filmmakers, production companies</b>, and other stakeholders such as <b>investors and actors/actresses</b> to make informed decisions with regard to content creation, marketing, investments, and engagement with the audience.\n",
    "\n",
    "The result of this research can be implemented further in other sectors as a form of <b>Transfer Learning</b>. For instance, it can be used to examine the positive and negative sentiment in other reviews such as music reviews and Application stores reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296d347",
   "metadata": {},
   "source": [
    "The implementation of this research will consist of the following parts:\n",
    "\n",
    "<b>Data Cleaning and Processing</b>: \n",
    "This section aims to obtain the data and prepare it for further analysis. The data will need to be cleaned, consistent, and balanced at the end. It will identify and remove irrelevant features while focusing on important ones. \n",
    "\n",
    "<b>Simple Textual Analysis</b>: Simple analysis without the use of machine learning and neural networks will be conducted. It would include analysis such as Lexical analysis and word frequency distribution.\n",
    "\n",
    "<b>Building Classfication Models</b>:  \n",
    "Multiple Machine Learning Classification models will be constructed and trained on the processed data. These models aim to categorize the comments on the movies into positive and negative sentiments, enabling the analysis of user opinions. \n",
    "\n",
    "<b>Performance Evaluation</b>: The models constructed will undergo evaluations and comparisons using metrics such as accuracy, recall, and F1-score, together with the baseline model. The best-performing model will be identified by its ability to accurately classify the comments into positive and negative sentiments.\n",
    "\n",
    "<b>Conclusion</b>: Final findings will be concluded from two perspectives, building the model for future use (Performance Evaluation) and analysis of current data (Simple Textual Analysis). It allows more informed conclusions regarding sentiment analysis and its applicability to movie comments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c057ba77",
   "metadata": {},
   "source": [
    "Word Count: 420"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf95f45",
   "metadata": {},
   "source": [
    "<h3 id=\"1.3\">1.3 Choice of Dataset</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eefbb1",
   "metadata": {},
   "source": [
    "It is essential to choose a good choice of data. A range of data from many websites was considered, including the Rotten Tomatoes movies and critic reviews dataset and Top Popular Movie Review Data Set from Kaggle. Ultimately, the Large Movie Review Dataset was chosen due to its large size. \n",
    "\n",
    "The dataset is available to download from [here](https://ai.stanford.edu/~amaas/data/sentiment/). It is in the compressed tar format. It contains movie reviews with their associated binary sentiment labels. The dataset contains 50,000 reviews split into 25k for training and 25k for testing. This data set is a balanced dataset with an equal number of contains labeled as positive and negative.\n",
    "\n",
    "The data is stored in a text document in two folders, one for 'pos', and another for 'neg'. Each document's name will contain its unique ID and the corresponding rating. As the data is not stored in the traditional CSV format, an algorithm will be needed to extract the information for the folder.\n",
    "\n",
    "The data is obtained from the Stanford Artificial Intelligence Laboratory, a laboratory at Stanford University. This a credible data that has also been widely used in research for many years. Although Dr. Andrew Maas, the first author of this dataset, did not explicitly specify the term of usage, the dataset is publicly available from the school's website.\n",
    "\n",
    "From an ethical point of view, the data did not include personal information about the creator of the review, making this have a high level of anonymity. Yet, a link is provided for every unique ID in the data, linking to the user comment page of the movie. This practice ensures the user remains largely anonymous while providing clues for data analysts to trace back to the movies if required.\n",
    "\n",
    "In summary, thorough research is conducted to find the Large Movie Review Dataset due to its large size and availability. This makes it an ideal source for sentimental analysis as it offers a substantial amount of diverse data with labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a7e47b",
   "metadata": {},
   "source": [
    "Word Count 327"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d6128e",
   "metadata": {},
   "source": [
    "<h3 id=\"1.4\">1.4 Evaluation Methodology</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517229d2",
   "metadata": {},
   "source": [
    "To effectively assess the performance of the models in this project Evaluation metrics such as accuracy, presision, recall and F1 score will be used. The confusion matrix will also be analysed. However, the main focus will be on comparing the accuracy across the models and the baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5961e262",
   "metadata": {},
   "source": [
    "With reference to the formula below, accuracy measures the overall correctness of the classification model by calculating the correctly classfied samples over all of the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3592f5",
   "metadata": {},
   "source": [
    "$$\n",
    " \\text{Accuracy} = \\frac{\\text{True Positives} + \\text{True Negatives}}{\\text{Total Samples}}\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa7f9a6",
   "metadata": {},
   "source": [
    "Precision, on the other hand, only considers those which are correctly classified as positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfbc5a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28788340",
   "metadata": {},
   "source": [
    "Recall finds those which are correctly labbeled as positive among those which are actually positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c439334",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94289206",
   "metadata": {},
   "source": [
    "F1 score provides a balanced measure of the model's performance by combining both precision and recall. It considers the model's ability to correctly identify positive instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c16974",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93359008",
   "metadata": {},
   "source": [
    "Confusion matrix provides the summary of the overall performance of the model by displaying the number for true positives, true negatives, false positives, and false negatives. It is a detailed breakdown of the models prediction against the actual sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2682397",
   "metadata": {},
   "source": [
    "In this study, accuracy will be the primary evaluation metric as it provides a balanced consideration of both positive and negative sentiments. However, during the optimization of the models, other metrics such as precision, recall, and F1-score may also be considered. Nevertheless, for the purpose of evaluation across all models, accuracy will be the sole metric utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee836a8a",
   "metadata": {},
   "source": [
    "Word Count: 246"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb4a98",
   "metadata": {},
   "source": [
    "<h2 id=\"implementation\">2. Implementation</h2>\n",
    "<h3 id=\"2.1\">2.1 Processing</h3>\n",
    "<h3 id=\"2.1.1\">2.1.1 Data extraction</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ecce03",
   "metadata": {},
   "source": [
    "Before implementing the machine learning algorithm for natural language processing, the Large Movie Review Dataset obtained from the Stanford Artificial Intelligence Laboratory will need to be extracted and cleaned. The libraries for the entire analysis are imported together first, however, only some libraries, such as os library for managing the system, random library for selecting a random sample of data and pandas for storing and handling data frames will be used in the extraction part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660ef232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library needed for data analysis\n",
    "\n",
    "# os is used for handling the system\n",
    "import os\n",
    "\n",
    "# random for randomly selecting the data\n",
    "import random\n",
    "\n",
    "# pandas for storing and handling the data in data frame\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib for visualising the data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Regular expression handling\n",
    "import re\n",
    "\n",
    "# Numpy for calculation\n",
    "import numpy as np\n",
    "\n",
    "# NLTK for natural language processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords #stop words removal\n",
    "from nltk.stem import WordNetLemmatizer #replace words with similar meaning\n",
    "from nltk.tokenize import word_tokenize #tokenizing the string\n",
    "from nltk import ne_chunk\n",
    "from nltk.tree import Tree\n",
    "from nltk.collocations import BigramCollocationFinder #collation calculation\n",
    "from nltk.metrics import BigramAssocMeasures #collation calculation\n",
    "from nltk.probability import FreqDist #distribution calculation\n",
    "\n",
    "# spliting of data into test and train dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# RNN\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer #tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences #padding\n",
    "from tensorflow.keras.models import Sequential #deeplearning model\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dropout, Dense #deeplearning layers\n",
    "from tensorflow.keras import regularizers # regularisation\n",
    "from tensorflow.keras.models import load_model # loading model for testingS\n",
    "\n",
    "# Navie Bayes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# BoW\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# comparison\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Bert\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_squared_error\n",
    "\n",
    "# wordcould display\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02267cf9",
   "metadata": {},
   "source": [
    "In this stage, data will be extracted and stored locally. The location of the data file is first specified to extract the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21b6e64",
   "metadata": {},
   "source": [
    "The entire dataset contains <b>50,000 data entries</b>, a <b>balanced split of 25,000 entires</b> are in the testing and training file. To speed up the development process, only one of the folders will be used. In the folder selected, a randome selection of files will conducted again to reduce the datasize to 10,000 (5000 positive, 5000 negative). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf1ebb",
   "metadata": {},
   "source": [
    "As this dataset is quite widely explored globally, there are advanced models such as pretrained tensor models developed based on this dataset. This report will thus attempt to <b>deploy a published pretrained model</b>. As these models are likely to be trained on data the train folder of the original dataset, this report will <b>use the test folder from original dataset</b> instead for both testing and training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folders\n",
    "pos_folder = r'C:\\Users\\xjie\\Documents\\SIM\\Y3S2\\nlp\\aclImdb\\test\\pos'\n",
    "neg_folder = r'C:\\Users\\xjie\\Documents\\SIM\\Y3S2\\nlp\\aclImdb\\test\\neg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f5c3c",
   "metadata": {},
   "source": [
    "<b>Format of data:</b> As the data obtained is in the form of <b>text document</b> (.txt file) stored in positive and negative sentiment folder with each individual file name as the rating and the ID, a file counter is needed to check for the length of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a8a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions;\n",
    "\n",
    "# Count the number of files in the data folder\n",
    "def count_files(folder_path):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Error: {folder_path} is not a valid directory.\")\n",
    "        return\n",
    "\n",
    "    file_count = 0\n",
    "\n",
    "    for _, _, files in os.walk(folder_path):\n",
    "        file_count += len(files)\n",
    "\n",
    "    return file_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3cde10",
   "metadata": {},
   "source": [
    "Using the function as define above, the number of the files in both positive and negative folder are obtained: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f13f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive data file avaliable\n",
    "file_count = count_files(pos_folder)\n",
    "print(f\"The number of files in positive data folder is: {file_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d30de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative data file avaliable \n",
    "file_count = count_files(neg_folder)\n",
    "print(f\"The number of files in nagtive data folder is: {file_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ac5c6",
   "metadata": {},
   "source": [
    "As this training data set is <b>too big</b> for the computer, only <b>5000 data</b> from positive and negative folder respectively will be selected to make the program runs faster. Then these data will be further seperated into test and training sets. These data will be selected using the random library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b4f8b2",
   "metadata": {},
   "source": [
    "Information such as the ID of the comment and the rating of the comment will be extracted from the file name using \"_\" as the separator, while the actual comment will be extracted by reading the file content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc4b11",
   "metadata": {},
   "source": [
    "Some helper functions are defined to extract the information and data from the data folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# Function to extract unique ID and rating from file name\n",
    "def extract_info(file_name):\n",
    "    id_rating = file_name.split('.')[0]\n",
    "    unique_id, rating = id_rating.split('_')\n",
    "    return int(unique_id), int(rating)\n",
    "\n",
    "# Function to extract the data from the file based on the aclImdb data structure\n",
    "def extract_files(folder, num_files, sentiment):   \n",
    "    files = random.sample(os.listdir(folder), num_files)\n",
    "    data = pd.DataFrame(columns=['Sentiment', 'Unique ID', 'Rating', 'Content'])\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read() # read content for the review\n",
    "        unique_id, rating = extract_info(file_name)  # get ID and rating from file name\n",
    "        file_data = pd.DataFrame({'Sentiment': [sentiment], 'Unique ID': [unique_id], 'Rating': [rating], 'Content': [content]})\n",
    "        data = pd.concat([data, file_data], ignore_index=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d48f69c",
   "metadata": {},
   "source": [
    "The following code randomly extract 5000 random data from the folder using the helper function defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91458ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data\n",
    "pos_data = extract_files(pos_folder, 5000, 'pos')\n",
    "neg_data = extract_files(neg_folder, 5000, 'neg')\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "raw_data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "\n",
    "# Display the start of the data\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a004d7",
   "metadata": {},
   "source": [
    "The raw data obtained from the dataset is thus extracted, however, cleaning is needed before extracting useful knowledge from the content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b506f4",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f51fc5",
   "metadata": {},
   "source": [
    "<h3 id=\"2.1.2\">2.1.2 Prelimary Data Exploration and Data Cleaning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4edab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the data\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcac1535",
   "metadata": {},
   "source": [
    "It was noted that both Unique ID and Content has duplicated values after the extraction as the frequency of the data is not 1. \n",
    "\n",
    "However, it is <b>not ideal</b> for the model to take in repeated reading in the content field as it does not add any more knowlegde to the model. Moreover, the original unique ID also do not provide much information after combining the data from both positive sentiment and negative sentiment.\n",
    "\n",
    "Thus, an algorithm will be implemented to check for these values and handle them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e18134e",
   "metadata": {},
   "source": [
    "<b>For duplicates in Unique ID</b>, as a <b>new ID will be assigned</b> as the index for the data frame, there is <b>no need</b> for the Unique ID from positive sentiment and negative sentiment folder. Thus, the <b>unique ID column will be dropped</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff0aa8",
   "metadata": {},
   "source": [
    "<b>For duplicates in content</b>, it will first find the duplicates, then remove the <b>first instance</b> of the duplicates. To ensure the overall dataset remain balanced, it will perform the random selection of data from the original data file again. These two functions will be <b>called recursively</b> until there is <b>no repetition</b> in the dataframe. The cleaned data will be saved in a new data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf405cd",
   "metadata": {},
   "source": [
    "<h4>Removing duplicates and old Unique ID</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d07247",
   "metadata": {},
   "source": [
    "The following code <b>removes</b> the unique ID from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a50992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unique ID column from the data\n",
    "org_ID_removed_data = raw_data.drop(\"Unique ID\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107d5528",
   "metadata": {},
   "source": [
    "The following function <b>finds</b> the dupicates and <b>returns</b> the duplicated pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d7309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "# Check for repetetion of data\n",
    "def find_duplicates(dataframe, column):\n",
    "    duplicates = dataframe[dataframe[column].duplicated(keep=False)]\n",
    "    duplicates_sorted = duplicates.sort_values(by=column)\n",
    "\n",
    "    if duplicates_sorted.empty:\n",
    "        print(\"No repeated data entry found.\")\n",
    "    else:\n",
    "        print(\"Repeated data entry(ies) found in \"+str(column))\n",
    "        duplicates_pairs = duplicates_sorted.groupby(column).apply(lambda x: x.reset_index(drop=True))\n",
    "        duplicates_pairs.reset_index(drop=True, inplace=True)\n",
    "        return duplicates_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99a5745",
   "metadata": {},
   "source": [
    "The following function <b>removes the duplicated data</b> and <b>add in data of the same size</b> from the positive or negative folder inorder to make the dataframe balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bafd4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "# replace duplicates with other values\n",
    "def get_balance_data_with_duplicates(duplicate_content, original_data, pos_folder, neg_folder):\n",
    "    # Remove the first occurrence of unique items in the duplicated content\n",
    "    data_to_remove = duplicate_content.drop_duplicates(subset='Content', keep='first')\n",
    "    org_ID_removed_data = original_data.drop_duplicates(subset='Content', keep='first')\n",
    "\n",
    "    # Count the number of pos and neg entries in 'data_to_remove'\n",
    "    pos_count = data_to_remove[data_to_remove['Sentiment'] == 'pos'].shape[0]\n",
    "    neg_count = data_to_remove[data_to_remove['Sentiment'] == 'neg'].shape[0]\n",
    "\n",
    "    # Add the removed duplicates such that the data is balanced\n",
    "    added_pos_data = extract_files(pos_folder, pos_count, 'pos')\n",
    "    added_neg_data = extract_files(neg_folder, neg_count, 'neg')\n",
    "\n",
    "    # Remove the 'Unique ID' column from added data\n",
    "    added_pos_data.drop(\"Unique ID\", axis=1, inplace=True)\n",
    "    added_neg_data.drop(\"Unique ID\", axis=1, inplace=True)\n",
    "\n",
    "    added_data = pd.concat([added_pos_data, added_neg_data], ignore_index=True)\n",
    "    balanced_data = pd.concat([org_ID_removed_data, added_data], ignore_index=True)\n",
    "\n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79891813",
   "metadata": {},
   "source": [
    "As there could still be duplicates present in the new files that are added, a recursive algorithm is used to check and replace the replicate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609de963",
   "metadata": {},
   "source": [
    "The following function will call get_balance_data_with_duplicates and find_duplicates functions will be called to check and replace the duplicated data until there is no more repeated entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1292a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recursively call the previouse two function untill data is balanced and no repetition\n",
    "def recursive_data_balancing(dataframe, column, pos_folder, neg_folder):\n",
    "    duplicates = find_duplicates(dataframe, column)\n",
    "\n",
    "    if duplicates is None:\n",
    "        print(\"No more duplicates found.\")\n",
    "        return dataframe\n",
    "\n",
    "    # Call get_balance_data_with_duplicates with the duplicate content\n",
    "    balanced_data = get_balance_data_with_duplicates(duplicates, dataframe, pos_folder, neg_folder)\n",
    "\n",
    "    # Recursively check for duplicates\n",
    "    print(\"Recursive call to balance the data.\")\n",
    "    return recursive_data_balancing(balanced_data, column, pos_folder, neg_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569844c4",
   "metadata": {},
   "source": [
    "Now, the last recursive function is called with the data extracted fed into the function. It will return a balanced dataset of positive and negative data with no repeatition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7f46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data = recursive_data_balancing(org_ID_removed_data, 'Content', pos_folder, neg_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f517a3",
   "metadata": {},
   "source": [
    "The algorithm and outputs confirms that a balanced dataset with no repetition was extracted from the data downloaded from the Stanford University AI Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc7c11",
   "metadata": {},
   "source": [
    "<h4>Simple statistic analysis</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c4a31",
   "metadata": {},
   "source": [
    "Besides the ensure balancing and no repetition of data, some other checks were also performed on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d8076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the overall information\n",
    "balanced_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba05f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double checking the total number of data entries\n",
    "print(\"Number of entries in 'Sentiment' column:\", balanced_data['Sentiment'].shape[0])\n",
    "print(\"Number of entries in 'Rating' column:\", balanced_data['Rating'].shape[0])\n",
    "print(\"Number of entries in 'Content' column:\", balanced_data['Content'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25248cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null data\n",
    "balanced_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c862b",
   "metadata": {},
   "source": [
    "The dataset extracted contains <b>3 columns</b> with <b>10000 rows</b>. There is <b>no null data</b> in all the data entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beda128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double checking for unique data\n",
    "balanced_data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aac0bfe",
   "metadata": {},
   "source": [
    "This section confirms that the recursive algorithm above is working to remove duplicate while ensuring a balanced data. There is repetition in the Content column in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4baacfb",
   "metadata": {},
   "source": [
    "The entries for the other two columns are examined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b92028",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2f2cc",
   "metadata": {},
   "source": [
    "This shows that there is a <b>balanced mix</b> of positive (pos) and negative (neg) data. The Rating is <b>between 1 to 4 and 7 to 10</b>. According the information in the readme file attached in the dataset downloaded, entries with rating <b>5 and 6</b> are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cacf3d",
   "metadata": {},
   "source": [
    "A <b>distribution</b> of the Rating in the form of <b>bar graph</b> and the propotion of each sentiment in the form of a <b>pie chart</b> is plotted for visualisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb246a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Ratings\n",
    "rating_counts = balanced_data['Rating'].value_counts().sort_index()\n",
    "\n",
    "# Distribution of Sentiment\n",
    "sentiment_counts = balanced_data['Sentiment'].value_counts()\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot Distribution of Ratings\n",
    "ax1.set_xticks(range(1, 11))\n",
    "ax1.set_xticklabels(range(1, 11))\n",
    "ax1.bar(rating_counts.index, rating_counts.values)\n",
    "ax1.set_xlabel('Rating', fontsize=12)\n",
    "ax1.set_ylabel('Count',  fontsize=12)\n",
    "ax1.set_title('Distribution of Ratings')\n",
    "\n",
    "# Plot Distribution of Sentiment\n",
    "ax2.pie(sentiment_counts.values, \n",
    "        labels=None, \n",
    "        autopct='%1.1f%%', \n",
    "        startangle=90) # no labels, set as 1 decimal place, title the angle by 90 degree\n",
    "ax2.set_title('Distribution of Sentiment')\n",
    "ax2.legend(sentiment_counts.index, loc=\"best\", fontsize=12)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995507fb",
   "metadata": {},
   "source": [
    "It can be seen that this dataframe contains 10000 with a <b>balanced distribution</b> of positive and negative sentiment data. The <b>most common rating</b> is 1 followed by 10. Both of them are the most frequent term in their sentiment respectively.\n",
    "\n",
    "There is also <b>no null data</b> in all three columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84334e13",
   "metadata": {},
   "source": [
    "<h4>Collation analysis:</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a8cea9",
   "metadata": {},
   "source": [
    "<b>Collation</b> is obtained using BigramAssocMeasures from the NLTK library to analyze the relationship between nearby texts. This is useful to <b>identify negations</b>, which can pose challenges in the sentimental analysis when tokenizing data into n-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e221a7b",
   "metadata": {},
   "source": [
    "For simplicity, the analysis will only focus on the negations for bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc55566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate collocations in a given text\n",
    "def calculate_collocations(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    finder = BigramCollocationFinder.from_words(words)\n",
    "    finder.apply_freq_filter(2)  # Adjust the frequency threshold as needed\n",
    "    collocations = finder.nbest(BigramAssocMeasures.pmi, 10)  \n",
    "    return collocations\n",
    "\n",
    "# Combine the content of balanced_data['Content'] into a single string\n",
    "text = ' '.join(balanced_data['Content'])\n",
    "\n",
    "# Calculate collocations for the combined text\n",
    "collocations = calculate_collocations(text)\n",
    "\n",
    "# Create a DataFrame to store the collocations and frequencies\n",
    "collocations_df = pd.DataFrame(collocations, columns=['Word 1', 'Word 2'])\n",
    "collocations_df['Frequency'] = collocations_df.apply(lambda row: text.count(' '.join(row)), axis=1)\n",
    "\n",
    "# Sort the DataFrame by frequency in descending order\n",
    "collocations_df = collocations_df.sort_values('Frequency', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e5629",
   "metadata": {},
   "source": [
    "The result is displayed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527252d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 5 collocations with frequencies\n",
    "collocations_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2749f9",
   "metadata": {},
   "source": [
    "Based on the analysis above, there <b>does not</b> seem to be any negations as there is no common occurance of terms such as \"not good\" or \"not nice\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76759cf6",
   "metadata": {},
   "source": [
    "<h4>Frequency analysis:</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1b1488",
   "metadata": {},
   "source": [
    "Next, the entries were tokenized to examine the common words used in the reviews using frequency distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56654e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the words in the balanced_data[\"Content\"] column\n",
    "all_words = nltk.word_tokenize(' '.join(balanced_data[\"Content\"]))\n",
    "\n",
    "# Calculate the frequency distribution of words\n",
    "freq_dist = FreqDist(all_words)\n",
    "\n",
    "# Get the 30 most common words\n",
    "most_common_words = freq_dist.most_common(30)\n",
    "\n",
    "# Extract the words and their frequencies\n",
    "words, frequencies = zip(*most_common_words)\n",
    "\n",
    "# Plot the number of occurrences\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(words, frequencies)\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top 30 Most Common Words')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d157c",
   "metadata": {},
   "source": [
    "It was noted that most of the common words were <b>punctuation marks</b> (such as \",\", \".\", \"<\" and \">\"), <b>determiners</b> (such as \"the\", \"that\", and \"this\") as well as <b>conjunctions</b> (such as \"and\", \"for\"). Thus a stopwords and punctuation removal is needed to obtain the part of the string that contains the most information. This will be done using the stopwords and Punkt tokenizer, which is a pre-trained sentence tokenizer available in NLTK.\n",
    "\n",
    "Other common words that are present in the reviews are <b>related to the subject domain</b> (movie review. Some of the examples of these words are \"movie\" and \"film\".\n",
    "\n",
    "It is also noted that besides the common stopwords and words that is related to the subject domain(moview review), there is also another commonly used term <b>\"br\"</b>. Further analysis of this term will thus be carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936878f",
   "metadata": {},
   "source": [
    "<h4>lexical analysis:</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349aa5c3",
   "metadata": {},
   "source": [
    "Lexical Diversity is calculated using the equation below. It measure of how diverse the vocabulary used in the positive and negative reviews by examining the ratio of unique words to the total number of words in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecd48f4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Lexical Diversity} = \\frac{\\text{Number of Unique Words}}{\\text{Total Number of Words}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d48b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data based on sentiment for balanced data\n",
    "positive_data = balanced_data[balanced_data['Sentiment'] == 'pos']\n",
    "negative_data = balanced_data[balanced_data['Sentiment'] == 'neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352f64c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to calculate the lexical diversity\n",
    "def calculate_lexical_diversity(text):\n",
    "    all_words = nltk.word_tokenize(text)\n",
    "    total_words = len(all_words)\n",
    "    unique_words = len(set(all_words))\n",
    "    lexical_diversity = unique_words / total_words\n",
    "    return lexical_diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc95c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lexical_diversity = calculate_lexical_diversity(' '.join(positive_data[\"Content\"]))\n",
    "neg_lexical_diversity = calculate_lexical_diversity(' '.join(negative_data[\"Content\"]))\n",
    "\n",
    "print(\"Lexical Diversity before cleaning (Positive Sentiment):\", pos_lexical_diversity)\n",
    "print(\"Lexical Diversity before cleaning (Negative Sentiment):\", neg_lexical_diversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5cf3a0",
   "metadata": {},
   "source": [
    "<h4>Cleaning for the use of tags</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb73bfc",
   "metadata": {},
   "source": [
    "Firstly, the data entries with term br is filtered out and displayed as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the entries containing \"br\"\n",
    "filtered_data = balanced_data[balanced_data[\"Content\"].str.contains(\"br\")]\n",
    "\n",
    "# Create a copy of the filtered DataFrame\n",
    "filtered_data = filtered_data.copy()\n",
    "\n",
    "# Extract the substring with 10 characters before and after \"br\"\n",
    "filtered_data.loc[:, \"Snippet\"] = filtered_data[\"Content\"].str.extract(r\"(.{0,10}br.{0,10})\")\n",
    "\n",
    "# Display the filtered data\n",
    "filtered_data[[\"Snippet\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787843b3",
   "metadata": {},
   "source": [
    "It is noticed that the dataset uses <b> &lt;br /&gt; tag </b> as a part of the content. This sytex is mostly used to symbolise a change of line. Thus, the &lt;br /&gt; will be <b>removed</b> as part of the stopwords removal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b714a1",
   "metadata": {},
   "source": [
    "To prevent other issues related to tags, a further check is conducted to verify other usage of < /> and <> using <b>regular expression</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08baba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for other uses of tags using the term \"< />\"\n",
    "# Filter the entries containing \"<\" and \"/>\"\n",
    "data_tags = balanced_data[balanced_data[\"Content\"].str.contains(\"<.*?/>\")]\n",
    "\n",
    "# Create a copy of the tags\n",
    "data_tags = data_tags.copy()\n",
    "\n",
    "# Extracting the substrings starts with \"<\" and end with \"/>\"\n",
    "data_tags[\"tags\"] = data_tags[\"Content\"].str.extract(r\"(<.*?/>)\")\n",
    "\n",
    "# Get the unique entries of tags\n",
    "tags = data_tags[\"tags\"].unique()\n",
    "\n",
    "# Print the unique entries\n",
    "for tag in tags:\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee52208",
   "metadata": {},
   "source": [
    "The above algorithm confirms that the <b>only tag used</b> is &lt;br /&gt;\n",
    "\n",
    "Thus, the data need to take not of the use of  &lt;br /&gt; when carry out stopwords removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46fa42",
   "metadata": {},
   "source": [
    "The frequency of the symbols for tags are also checked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6944f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the occurrences of tag markings\n",
    "punctuation_occurrences = {\n",
    "    \"/\": freq_dist[\"/\"],\n",
    "    \"<\": freq_dist[\"<\"],\n",
    "    \">\": freq_dist[\">\"]\n",
    "}\n",
    "\n",
    "print(\"Occurrences of specific punctuation marks:\")\n",
    "for punctuation, count in punctuation_occurrences.items():\n",
    "    print(f\"{punctuation}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf12d9",
   "metadata": {},
   "source": [
    "From the algorithm above, it was noticed that the use of < and > were largely the same while the use of / is slightly higher.\n",
    "\n",
    "This could indicate <b>other usage</b> of \"/\" besides tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41899415",
   "metadata": {},
   "source": [
    "Thus, the entire data is filtered again using regular expression which categorises every possible conbinations of the uses of \"/\" such as number / number and number / special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab581e9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking other uses\n",
    "content_column = balanced_data['Content']\n",
    "\n",
    "# Define the categories\n",
    "categories = {\n",
    "    'num/num': r'(?P<before>\\d+(\\.\\d+)?)/(?P<after>\\d+(\\.\\d+)?)',\n",
    "    'num/special': r'(?P<before>\\d+(\\.\\d+)?)/(?P<after>[\\W\\t])',\n",
    "    'special/num': r'(?P<before>[\\W\\t])/(?P<after>\\d+(\\.\\d+)?)',\n",
    "    'num/alpha': r'(?P<before>\\d+(\\.\\d+)?)/(?P<after>[a-zA-Z])',\n",
    "    'alpha/num': r'(?P<before>[a-zA-Z])/(?P<after>\\d+(\\.\\d+)?)',\n",
    "    'alpha/special': r'(?P<before>[a-zA-Z])/(?P<after>[^\\w\\s\\t])',\n",
    "    'special/alpha': r'(?P<before>[^\\w\\s\\t])/(?P<after>[a-zA-Z\\s])',\n",
    "    'alpha/alpha': r'(?P<before>[a-zA-Z])/(?P<after>[a-zA-Z])',\n",
    "    'special/special': r'(?P<before>[^\\w\\s\\t])/(?P<after>[^\\w\\s\\t])',\n",
    "    'space/alpha': r'(?P<before>\\s)/(?P<after>[a-zA-Z])',\n",
    "    'alpha/space': r'(?P<before>[a-zA-Z])/(?P<after>\\s)',\n",
    "    'space/space': r'(?P<before>[\\s\\t])/(?P<after>[\\s\\t])'\n",
    "}\n",
    "\n",
    "# Categorize the strings and extract characters before and after \"/\"\n",
    "results = []\n",
    "for category, pattern in categories.items():\n",
    "    matches = content_column.str.extractall(pattern)\n",
    "    if not matches.empty:\n",
    "        matches = matches.reset_index()\n",
    "        matches = matches.rename(columns={'level_0': 'index'})\n",
    "        matches = matches[['index', 'before', 'after']]\n",
    "        matches['category'] = category\n",
    "        results.append(matches)\n",
    "\n",
    "# Combine the results into a single dataframe\n",
    "if results:\n",
    "    combined_results = pd.concat(results)\n",
    "    combined_results = combined_results.reset_index(drop=True)  # Reset the index\n",
    "else:\n",
    "    combined_results = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb9797",
   "metadata": {},
   "source": [
    "The frequency of the isage can be determined using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca012b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = combined_results['category'].value_counts().reset_index()\n",
    "category_counts.columns = ['category', 'count']\n",
    "category_counts = category_counts.sort_values('count', ascending=False)\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76092ca4",
   "metadata": {},
   "source": [
    "The most common usage of the \"/\" is examined and shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_a_df = combined_results[combined_results['category'] == 'alpha/alpha'].copy()\n",
    "a_a_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aaa0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_num_df = combined_results[combined_results['category'] == 'num/num'].copy()\n",
    "num_num_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f60368b",
   "metadata": {},
   "source": [
    "With that in mind, the original data was re-examined and realised the most common usage of\"/\" is for <b>choices between two words</b> (Eg. June/July), while the second most common usage is <b>two numbers</b> to show a rating (Eg. 8.5/10). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b28619f",
   "metadata": {},
   "source": [
    "Thus, when carrying out text processing pipelines later, <b>&lt;br /&gt; will be removed </b>as it is tag that provides little insights about the text. Moreover, numbers around \"/\" in the form of <b>number / number</b> will also be <b>removed</b> as it could provide information about the rating given by the viewer which should not be seen by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf705a",
   "metadata": {},
   "source": [
    "A column in the dataframe is created to store the data to be removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edefe824",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_num_df['string_removal'] = num_num_df['before'] + '/' + num_num_df['after']\n",
    "num_num_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f5bae",
   "metadata": {},
   "source": [
    "The data is now ready to be tokenized and transformed into a simpler term for a more detailed Natural Language Processing analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdca10b",
   "metadata": {},
   "source": [
    "<h4>Stopword removal and lemmatization</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e673d8",
   "metadata": {},
   "source": [
    "Stopwords removal and lemmatization are two important steps in Natural language processing. \n",
    "\n",
    "Stop words removal removes the commonly occured words that does not have significant contribution to the meaning of the text, such as \"a\", \"the\",\"is\". This process reduces noise and shortens the input text size. The overall unique number of words decreases, thus lexical diversity will also decreases.\n",
    "\n",
    "Lemmatization reduces the words into there base or root form. The variations in words will thus decrease, also result in a <b>decrease in lexical diversity</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd95927f",
   "metadata": {},
   "source": [
    "The list of words will be downloaded from NLTK library to carry out this process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086195c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('stopwords', quiet=True) # Stop words removal\n",
    "nltk.download('wordnet', quiet=True) # Lemmatization\n",
    "nltk.download('words', quiet=True) # Spelling check\n",
    "nltk.download('maxent_ne_chunker', quiet=True) # Expand short forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08203ff2",
   "metadata": {},
   "source": [
    "Some functions are needed to carry out the stop word removal and lemmatization. As the effects of every steps are evaluated, these steps could be called more than once. Thus, all of them are in the form of functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8480ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "# To change short forms to full forms\n",
    "def expand_short_forms(word, previous_word):\n",
    "    if word == \"'s\":\n",
    "        # Check if the previous word is a proper noun or named entity\n",
    "        if previous_word[0].isupper() or isinstance(ne_chunk([(previous_word, '')]), Tree):\n",
    "            # Likely indicating possession\n",
    "            return word\n",
    "        else:\n",
    "            # Likely contraction of \"is\"\n",
    "            return \"is\"\n",
    "    elif word == \"n't\":\n",
    "        return \"not\"\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f4224b",
   "metadata": {},
   "source": [
    "The actual code for text processing pipelines are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28265a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "# Remove specific strings identified\n",
    "def remove_string_entries(text, string):\n",
    "    if string is not None:\n",
    "        text = text.replace(string, '')\n",
    "    return text\n",
    "\n",
    "# remove speficific elements identified in data frame\n",
    "def remove_elements(text, column):\n",
    "    if column is not None:\n",
    "        for element in column:\n",
    "            text = text.replace(element, '')\n",
    "    return text\n",
    "\n",
    "# convert all entryies to lower case\n",
    "def convert_to_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "# call the expand_short_forms function above on the tokenised words and expand into full forms\n",
    "def expand_short_forms_in_text(text):\n",
    "    words = text.split()\n",
    "    expanded_words = [expand_short_forms(word, words[i-1]) if i > 0 else word for i, word in enumerate(words)]\n",
    "    return ' '.join(expanded_words)\n",
    "\n",
    "# remove special characters\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^a-z0-9]', ' ', text)\n",
    "\n",
    "# tokenizing text\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# less meaningful stop words removal using nltk\n",
    "def remove_stop_words(words):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return (word for word in words if word not in stop_words)\n",
    "\n",
    "# lemmatizing the words into base form using nltk\n",
    "def lemmatize_words(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "# joining the words back\n",
    "def combine_words(words):\n",
    "    return ' '.join(word for word in words)\n",
    "\n",
    "# remove spaces left in the removal proceses\n",
    "def remove_extra_spaces(text):\n",
    "    text = text.strip()\n",
    "    return re.sub(r'\\s+', ' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86946ae5",
   "metadata": {},
   "source": [
    "Firstly, the string <b>\" &lt;br /&gt;\" and ratings are removed</b> as identified in the word statistic analysis above. These also <b>removes the special characters</b>. The entires in the balanced data runs through iterations of cleaning process to <b>remove these strings</b>. On the other hand, the entries are also converted to <b>full forms</b> and in <b>small case.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6800e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning for specific strings, change to lower case full forms and remove special characters\n",
    "def text_processing_pipeline_no_token(text, string=None, column=None):\n",
    "    text = remove_string_entries(text, string)\n",
    "    text = remove_elements(text, column)\n",
    "    text = convert_to_lower_case(text)\n",
    "    text = expand_short_forms_in_text(text)\n",
    "    text = remove_special_characters(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the balanced data\n",
    "processed_data = balanced_data.copy()\n",
    "\n",
    "# Iteratively run the processing pipeline on every entry of content\n",
    "for i in range(len(balanced_data)):\n",
    "    processed_data.loc[i, 'Content'] = text_processing_pipeline_no_token(\n",
    "        processed_data.loc[i, 'Content'], \"<br />\", num_num_df['string_removal']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636bf429",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lexical_diversity_part1 = calculate_lexical_diversity(' '.join(processed_data[processed_data['Sentiment'] == 'pos'][\"Content\"]))\n",
    "neg_lexical_diversity_part1 = calculate_lexical_diversity(' '.join(processed_data[processed_data['Sentiment'] == 'neg'][\"Content\"]))\n",
    "\n",
    "print(\"Lexical Diversity before cleaning (Positive Sentiment):\", pos_lexical_diversity_part1)\n",
    "print(\"Lexical Diversity before cleaning (Negative Sentiment):\", neg_lexical_diversity_part1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0891719b",
   "metadata": {},
   "source": [
    "The lexical diversity <b>decresed by about 0.009</b> after this cleaning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6786b6",
   "metadata": {},
   "source": [
    "Then, the string is tokenised for lemmatisation and stopwords removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7729d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise for lemmatisation to reduce word forms\n",
    "def tpl_lemma(text):\n",
    "    words = tokenize_text(text)\n",
    "    words = lemmatize_words(words)\n",
    "    processed_text = combine_words(words)\n",
    "    processed_text = remove_extra_spaces(processed_text)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4952b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively run the preprocessing on every entry of content\n",
    "for i in range(len(processed_data)):\n",
    "    processed_data.loc[i, 'Content'] = tpl_lemma(processed_data.loc[i, 'Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36235122",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lexical_diversity = calculate_lexical_diversity(' '.join(processed_data[processed_data['Sentiment'] == 'pos'][\"Content\"]))\n",
    "neg_lexical_diversity = calculate_lexical_diversity(' '.join(processed_data[processed_data['Sentiment'] == 'neg'][\"Content\"]))\n",
    "\n",
    "print(\"Lexical Diversity before cleaning (Positive Sentiment):\", pos_lexical_diversity)\n",
    "print(\"Lexical Diversity before cleaning (Negative Sentiment):\", neg_lexical_diversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d01250",
   "metadata": {},
   "source": [
    "The lexical diversity <b>decresed by about 0.003</b> after lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59528bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise for stopwords removal \n",
    "def tpl_stopword(text):\n",
    "    words = tokenize_text(text)\n",
    "    words = remove_stop_words(words)\n",
    "    processed_text = combine_words(words)\n",
    "    processed_text = remove_extra_spaces(processed_text)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ddd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively run the preprocessing on every entry of content\n",
    "for i in range(len(processed_data)):\n",
    "    processed_data.loc[i, 'Content'] = tpl_stopword(processed_data.loc[i, 'Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d63859",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lexical_diversity = calculate_lexical_diversity(' '.join(processed_data[processed_data['Sentiment'] == 'pos'][\"Content\"]))\n",
    "neg_lexical_diversity = calculate_lexical_diversity(' '.join(processed_data[processed_data['Sentiment'] == 'neg'][\"Content\"]))\n",
    "\n",
    "print(\"Lexical Diversity before cleaning (Positive Sentiment):\", pos_lexical_diversity)\n",
    "print(\"Lexical Diversity before cleaning (Negative Sentiment):\", neg_lexical_diversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d9638",
   "metadata": {},
   "source": [
    "The lexical diversity <b>increased by about 0.026</b> after stopword removal. This is a irregular trend which the report will analys in detail later. Although the lexical diversity increased, the stopwords removal process is still needed as the analysis in the bar plot of the Top 30 common words above showed that <b>most of the commonly occured words are actually stop words</b>. Without removing stop words will <b>introduce a lot of noise</b> in the model later. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adf86f0",
   "metadata": {},
   "source": [
    "The analysis for lexical diversity can be found in <a href=\"#2.1.3\">2.1.3 Vocabulary statistic</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09035598",
   "metadata": {},
   "source": [
    "the following algorithm is used to check if the text has all being processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5742c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the success of text processing\n",
    "success_count = 0\n",
    "for original_text, processed_text in zip(balanced_data['Content'], processed_data['Content']):\n",
    "\n",
    "    if original_text == processed_text:\n",
    "        print(\"Text processing failed\")\n",
    "    else:\n",
    "        success_count +=1\n",
    "if success_count == len(processed_data['Content']):\n",
    "    print(\"Text processing success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8c0968",
   "metadata": {},
   "source": [
    "<h3 id=\"2.1.3\">2.1.3 Vocabulary statistic</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc1218c",
   "metadata": {},
   "source": [
    "<h4>lexical analysis:</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2419fb",
   "metadata": {},
   "source": [
    "This is interesting to see a significant and dramatic incrase in lexical diversity after stopwords removal. In most cases, the stopwards removal process <b>should decrease the lexical diversity</b>, however, <b>it increased there</b>. With reference to the equation below, lexical diversity is the number of unique words over the total number of words, a significant increase in lexical diversity after stopwords removal could mean that the original text contains <b>high proportion of stopwords as compared to total word count</b>. \n",
    "\n",
    "In this case, stop words removal process is carried out in short strings of text which is originated from <b>movie reviews</b>. The text of this from are generally short, which is likely to have a <b>higher proportion of stop words</b> as compared to long passage. \n",
    "\n",
    "This assumption is confirmed by the plot for top 30 common words in <a href=\"#2.1.3\">section 2.1.3</a> which shows a significant propotion of stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420bd208",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Lexical Diversity} = \\frac{\\text{Number of Unique Words}}{\\text{Total Number of Words}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bc0793",
   "metadata": {},
   "source": [
    "<h4>frequency distribution</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e75ea1",
   "metadata": {},
   "source": [
    "Checking the most common words and frequency distribution after tokenizing, lemmatizing and stopwords removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b4ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data based on sentiment for balanced data\n",
    "positive_data = processed_data[processed_data['Sentiment'] == 'pos']\n",
    "negative_data = processed_data[processed_data['Sentiment'] == 'neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de5bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the words in the positive_data[\"Content\"] column\n",
    "positive_words = nltk.word_tokenize(' '.join(positive_data[\"Content\"]))\n",
    "positive_freq_dist = FreqDist(positive_words)\n",
    "positive_common_words = positive_freq_dist.most_common(15)\n",
    "positive_words, positive_frequencies = zip(*positive_common_words)\n",
    "\n",
    "# Tokenize the words in the negative_data[\"Content\"] column\n",
    "negative_words = nltk.word_tokenize(' '.join(negative_data[\"Content\"]))\n",
    "negative_freq_dist = FreqDist(negative_words)\n",
    "negative_common_words = negative_freq_dist.most_common(15)\n",
    "negative_words, negative_frequencies = zip(*negative_common_words)\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot for positive sentiments\n",
    "ax1.bar(positive_words, positive_frequencies)\n",
    "ax1.set_xlabel('Words')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Top 15 Most Common Words (Positive Sentiment)')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot for negative sentiments\n",
    "ax2.bar(negative_words, negative_frequencies)\n",
    "ax2.set_xlabel('Words')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Top 15 Most Common Words (Negative Sentiment)')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Adjust the layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3637a71",
   "metadata": {},
   "source": [
    "From above, the most common occurance of words are film and movie. <b>Most</b> of the common words in both sentiment review dataset have a <b>neutral connotation</b>. For the top 15 most commonly used words, <b>two words</b> (good, great) in the positive sentiment data set have a <b>positive connotation</b> while there is only <b>one word</b> in the negative sentiment data set has a <b>negative connotation</b>. It is interesting to see that one word (good) with string positive connotation are present in the negative sentiment dataset. Assuming the dataset is labbeled correctly, this could be due to the <b>problem of negation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b378c",
   "metadata": {},
   "source": [
    "The plot also confirms the result of stopwords removal and othere data cleaning technics. There is <b>no words</b> in shown in the graph that is a <b>stop word or tag and punctuation mark</b>. The words are also <b>all in lower case</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85140591",
   "metadata": {},
   "source": [
    "A word cloud is generated to show the distribution of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ab69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word cloud for positive sentiments\n",
    "positive_wordcloud = WordCloud(width=800, height=400, background_color='white',colormap='inferno').generate(' '.join(positive_words))\n",
    "\n",
    "# Generate word cloud for negative sentiments\n",
    "negative_wordcloud = WordCloud(width=800, height=400, background_color='white',colormap='viridis').generate(' '.join(negative_words))\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot for positive sentiments\n",
    "ax1.imshow(positive_wordcloud, interpolation='bilinear')\n",
    "ax1.set_title('Word Cloud (Positive Sentiment)')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Plot for negative sentiments\n",
    "ax2.imshow(negative_wordcloud, interpolation='bilinear')\n",
    "ax2.set_title('Word Cloud (Negative Sentiment)')\n",
    "ax2.axis('off')\n",
    "\n",
    "# Adjust the layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ee2e5",
   "metadata": {},
   "source": [
    "<h4>Preparing data for Machine Learning:</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2dd9c",
   "metadata": {},
   "source": [
    "The Machine Learning Task is to <b>predict the sentiment based on the input data in the form of text</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f417077",
   "metadata": {},
   "source": [
    "Thus, the Content column is the <b>feature</b> to be learn and the Sentiment column is the <b>target variable/b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa659568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting sentiment base on the content, thus X (features) is the content and y (target variable) is the sentiment\n",
    "X = processed_data['Content']\n",
    "y = processed_data['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1821b524",
   "metadata": {},
   "source": [
    "80% of the data will be used for training while 20% of the data is stored for testing of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d9474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing data with a test size of 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a6abfd",
   "metadata": {},
   "source": [
    "To achieve consistency, data is saved in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e0e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in testing and training data in a new dataframe\n",
    "train_data = pd.DataFrame({'Content': X_train, 'Sentiment': y_train})\n",
    "test_data = pd.DataFrame({'Content': X_test, 'Sentiment': y_test})\n",
    "# Save data in csv file\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c3d82",
   "metadata": {},
   "source": [
    "<h3 id=\"2.2\">2.2 Baseline Performance</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e1bd86",
   "metadata": {},
   "source": [
    "To Evaluate the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119dd238",
   "metadata": {},
   "source": [
    "Evaluation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06181d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred):\n",
    "    # Calculate accuracy\n",
    "    accuracy = (y_true == y_pred).mean()\n",
    "\n",
    "    # Construct confusion matrix\n",
    "    confusion_matrix = pd.crosstab(y_true, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"=\" * 50)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "    return accuracy, confusion_matrix, precision, recall, f1, mse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7368f1",
   "metadata": {},
   "source": [
    "Deploying the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('textattack/bert-base-uncased-imdb')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('textattack/bert-base-uncased-imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ba6605",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_data.csv')\n",
    "content_test = test_data['Content'].tolist()\n",
    "sentiment_test = test_data['Sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d288ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists for predictions and evaluation metrics\n",
    "predictions = []\n",
    "y_true = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7617f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the test data\n",
    "for content, sentiment in zip(content_test, sentiment_test):\n",
    "    # Encode the content using the tokenizer\n",
    "    tokens = tokenizer.encode_plus(content, add_special_tokens=True, padding='max_length', max_length=128, truncation=True, return_tensors='pt')\n",
    "    input_ids = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    prediction = outputs.logits.argmax(dim=1).item()\n",
    "\n",
    "    # Append the prediction and true label to the lists\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23361fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convert labels from strings to numerical values\n",
    "sentiment_encoded = label_encoder.fit_transform(sentiment_test)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "y_pred = np.array(predictions)\n",
    "y_true = np.array(sentiment_encoded)  # Use the encoded labels instead of sentiment_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa71b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the evaluation function\n",
    "accu_BERT, confuM_BERT, pre_BERT, recall_BERT, f1_BERT, mse_BERT = evaluation(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ce00c",
   "metadata": {},
   "source": [
    "<h3 id=\"2.3\">2.3 Classification approach</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e032673",
   "metadata": {},
   "source": [
    "Training and running the model RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71afbcb0",
   "metadata": {},
   "source": [
    "stopwords removal - high tf is likely to be the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e98df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "\n",
    "# Extract the content and sentiment columns\n",
    "content = train_data['Content'].tolist()\n",
    "sentiment = train_data['Sentiment'].tolist()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(content, sentiment, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f564f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=4000)\n",
    "\n",
    "# Fit the vectorizer on the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train).toarray()\n",
    "\n",
    "# Transform the validation data using the fitted vectorizer\n",
    "X_val_tfidf = vectorizer.transform(X_val).toarray()\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_train_reshaped = X_train_tfidf.reshape(X_train_tfidf.shape[0], 1, X_train_tfidf.shape[1])\n",
    "X_val_reshaped = X_val_tfidf.reshape(X_val_tfidf.shape[0], 1, X_val_tfidf.shape[1])\n",
    "\n",
    "# Convert sentiment labels to numeric\n",
    "sentiment_mapping = {'pos': 1, 'neg': 0}\n",
    "y_train_numeric = np.array([sentiment_mapping[sent] for sent in y_train])\n",
    "y_val_numeric = np.array([sentiment_mapping[sent] for sent in y_val])\n",
    "y_test_numeric = np.array([sentiment_mapping[sent] for sent in sentiment_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59789c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=32, dropout=0.2, recurrent_dropout=0.3, input_shape=(1, X_train_tfidf.shape[1])))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train_numeric, validation_data=(X_val_reshaped, y_val_numeric),\n",
    "          epochs=20, verbose=1, batch_size=128)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"RNN_tf_idf.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = load_model(\"RNN_tf_idf.h5\")\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Extract the content and sentiment columns\n",
    "content_test = test_data['Content'].tolist()\n",
    "sentiment_test = test_data['Sentiment'].tolist()\n",
    "\n",
    "# Transform the test data using the fitted vectorizer\n",
    "test_tfidf = vectorizer.transform(content_test).toarray()\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "test_reshaped = test_tfidf.reshape(test_tfidf.shape[0], 1, test_tfidf.shape[1])\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred_prob = model.predict(test_reshaped)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "y_pred = y_pred.flatten()  # Flatten the predictions to match the shape of y_test_numeric\n",
    "\n",
    "# Call the evaluation function\n",
    "accu_RNN, confuM_RNN, prec_RNN, recall_RNN, f1_RNN, mse_RNN = evaluation(y_test_numeric, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=32, dropout=0.2, recurrent_dropout=0.3, \n",
    "               input_shape=(1, X_train_tfidf.shape[1])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=64, activation='relu', \n",
    "                kernel_regularizer=regularizers.l1(0.02)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train_numeric, validation_data=(X_val_reshaped, y_val_numeric),\n",
    "          epochs=20, verbose=1, batch_size=128)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"trained_model_RNN_tf_idf.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6218e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = load_model(\"trained_model_RNN_tf_idf.h5\")\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Extract the content and sentiment columns\n",
    "content_test = test_data['Content'].tolist()\n",
    "sentiment_test = test_data['Sentiment'].tolist()\n",
    "\n",
    "# Transform the test data using the fitted vectorizer\n",
    "test_tfidf = vectorizer.transform(content_test).toarray()\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "test_reshaped = test_tfidf.reshape(test_tfidf.shape[0], 1, test_tfidf.shape[1])\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred_prob = model.predict(test_reshaped)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "y_pred = y_pred.flatten()  # Flatten the predictions to match the shape of y_test_numeric\n",
    "\n",
    "# Call the evaluation function\n",
    "accuracy_RNN_tu, confuM_RNN_tu, precision_RNN_tu, recall_RNN_tu, f1_RNN_tu, mse_RNN_tu = evaluation(y_test_numeric, \n",
    "                                                                                     y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c9c86",
   "metadata": {},
   "source": [
    "tf-idf measure the originality of the words. TF(t,d)*IDF(t) identify sigificant words. Number of times word appear/total words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447c68e",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Vectorize the content data\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_val_vectorized = vectorizer.transform(X_val)\n",
    "\n",
    "# Convert string labels to numeric format\n",
    "label_encoder = LabelEncoder()\n",
    "y_val_numeric = label_encoder.fit_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d87377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of kernels to compare\n",
    "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "\n",
    "# Store the best performing kernel and its accuracy\n",
    "best_kernel = None\n",
    "best_accuracy = 0.0\n",
    "best_modelSVM = None\n",
    "\n",
    "# Iterate over each kernel\n",
    "for kernel in kernels:\n",
    "    # Train an SVM classifier with the current kernel\n",
    "    model = SVC(kernel=kernel)\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    val_predictions = model.predict(X_val_vectorized)\n",
    "    val_predictions_numeric = label_encoder.transform(val_predictions)\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    accuracy = accuracy_score(y_val_numeric, val_predictions_numeric)\n",
    "    print(\"Validation Accuracy for\", kernel, \"kernel:\", accuracy)\n",
    "\n",
    "    # Check if the current kernel outperforms the previous best kernel\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_kernel = kernel\n",
    "        best_modelSVM = model\n",
    "\n",
    "# Fit the best model\n",
    "best_modelSVM.fit(X_train_vectorized, y_train)\n",
    "# Output the best performing kernel\n",
    "print(\"Best Performing Kernel:\", best_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f407491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the content and sentiment columns\n",
    "X_test = test_data['Content']\n",
    "y_test = test_data['Sentiment']\n",
    "\n",
    "# Vectorize the testing data\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "test_predictions = best_modelSVM.predict(X_test_vectorized)\n",
    "test_predictions_numeric = label_encoder.transform(test_predictions)\n",
    "\n",
    "# Convert string labels of the testing set to numeric format\n",
    "y_test_numeric = label_encoder.transform(y_test)\n",
    "\n",
    "# Calculate accuracy on the testing set\n",
    "accuracy_test = accuracy_score(y_test_numeric, test_predictions_numeric)\n",
    "\n",
    "# Print the evaluation metrics for the testing set\n",
    "accuracy_SVM, confuM_SVM, precision_SVM, recall_SVM, f1_SVM, mse_SVM = evaluation(y_test_numeric, test_predictions_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d243fd",
   "metadata": {},
   "source": [
    "Logistic Regression (Bag of word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad8738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the vectorized data\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_scaled = scaler.fit_transform(X_train_vectorized)\n",
    "X_val_scaled = scaler.transform(X_val_vectorized)\n",
    "\n",
    "# Convert string labels to numeric format\n",
    "label_encoder = LabelEncoder()\n",
    "y_val_numeric = label_encoder.fit_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the solvers to try\n",
    "solvers = ['liblinear', 'sag', 'saga']\n",
    "\n",
    "best_solver = None\n",
    "best_accuracy = 0.0\n",
    "best_modelLR = None\n",
    "\n",
    "\n",
    "for solver in solvers:\n",
    "    # Train a Logistic Regression classifier with the current solver\n",
    "    model = LogisticRegression(max_iter=1000, solver=solver)\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    val_predictions = model.predict(X_val_vectorized)\n",
    "    val_predictions_numeric = label_encoder.transform(val_predictions)\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    accuracy = accuracy_score(y_val_numeric, val_predictions_numeric)\n",
    "    print(\"Validation Accuracy with\", solver, \"solver:\", accuracy)\n",
    "    \n",
    "    # Check if the current solver achieved the best accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_solver = solver\n",
    "        best_modelLR = model\n",
    "        \n",
    "# Fit the best model\n",
    "best_modelLR.fit(X_train_vectorized, y_train)\n",
    "print(\"Best Solver:\", best_solver)\n",
    "print(\"Best Validation Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "test_predictions = best_modelLR.predict(X_test_vectorized)\n",
    "test_predictions_numeric = label_encoder.transform(test_predictions)\n",
    "\n",
    "# Convert string labels of the testing set to numeric format\n",
    "y_test_numeric = label_encoder.transform(y_test)\n",
    "\n",
    "# Calculate accuracy on the testing set\n",
    "accuracy_test = accuracy_score(y_test_numeric, test_predictions_numeric)\n",
    "\n",
    "# Print the evaluation metrics for the testing set\n",
    "accuracy_BoW, confuM_BoW, precision_BoW, recall_BoW, f1_BoW, mse_BoW = evaluation(y_test_numeric,\n",
    "                                                                                            test_predictions_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2858395e",
   "metadata": {},
   "source": [
    "<h2 id=\"Conc\">3. Conclusion</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8554b794",
   "metadata": {},
   "source": [
    "<h3 id=\"3.1\">3.1 Evaluation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23567172",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of evaluation metrics\n",
    "precision_scores = [precision_RNN, precision_RNN_tu, precision_SVM, precision_BoW, precision_BERT]\n",
    "recall_scores = [recall_RNN, recall_RNN_tu, recall_SVM, recall_BoW, recall_BERT]\n",
    "f1_scores = [f1_RNN, f1_RNN_tu, f1_SVM, f1_BoW, f1_BERT]\n",
    "mse_scores = [mse_RNN, f1_RNN_tu, mse_SVM, mse_BoW, mse_BERT]\n",
    "\n",
    "# create a list of model name\n",
    "models = ['RNN (Overfitted)', 'RNN (L2 regularised)', 'SVM',\n",
    "          'BoW', 'BERT (Baseline)']\n",
    "\n",
    "# Set the figure size and create subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Set the width of each bar\n",
    "bar_width = 0.4\n",
    "\n",
    "# Set the position of each bar on the x-axis\n",
    "r = np.arange(len(models))\n",
    "\n",
    "# Initialize the bottom position of the bars\n",
    "bottom = np.zeros(len(models))\n",
    "\n",
    "# Plot precision scores\n",
    "axs[0, 0].bar(r, precision_scores, bottom=bottom, color='b', width=bar_width)\n",
    "axs[0, 0].bar(r[-1], precision_scores[-1], color='orange', width=bar_width)\n",
    "axs[0, 0].axhline(y=precision_scores[-1], color='red', linestyle='-', linewidth=1)\n",
    "axs[0, 0].set_ylim(0.8, 0.9)  \n",
    "axs[0, 0].set_xlabel('Models')\n",
    "axs[0, 0].set_xticks(r , models, rotation=300, ha='left', va='top')\n",
    "axs[0, 0].set_ylabel('Precision')\n",
    "axs[0, 0].set_title('Comparison of Precision Scores for Different Models')\n",
    "\n",
    "# Plot recall scores\n",
    "axs[0, 1].bar(r, recall_scores, bottom=bottom, color='b', width=bar_width)\n",
    "axs[0, 1].bar(r[-1], recall_scores[-1], color='orange', width=bar_width)\n",
    "axs[0, 1].axhline(y=recall_scores[-1], color='red', linestyle='-', linewidth=1)\n",
    "axs[0, 1].set_ylim(0.8, 0.9)  # Adjust the limits\n",
    "axs[0, 1].set_xlabel('Models')\n",
    "axs[0, 1].set_xticks(r , models, rotation=300, ha='left', va='top')\n",
    "axs[0, 1].set_ylabel('Recall')\n",
    "axs[0, 1].set_title('Comparison of Recall Scores for Different Models')\n",
    "\n",
    "# Plot F1 scores\n",
    "axs[1, 0].bar(r, f1_scores, bottom=bottom, color='b', width=bar_width)\n",
    "axs[1, 0].bar(r[-1], f1_scores[-1], color='orange', width=bar_width)\n",
    "axs[1, 0].axhline(y=f1_scores[-1], color='red', linestyle='-', linewidth=1)\n",
    "axs[1, 0].set_ylim(0.8, 0.9) \n",
    "axs[1, 0].set_xlabel('Models')\n",
    "axs[1, 0].set_xticks(r , models, rotation=300, ha='left', va='top')\n",
    "axs[1, 0].set_ylabel('F1-score')\n",
    "axs[1, 0].set_title('Comparison of F1 Scores for Different Models')\n",
    "\n",
    "# Plot MSE scores\n",
    "axs[1, 1].bar(r, mse_scores, bottom=bottom, color='b', width=bar_width)\n",
    "axs[1, 1].bar(r[-1], mse_scores[-1], color='orange', width=bar_width)\n",
    "axs[1, 1].axhline(y=mse_scores[-1], color='red', linestyle='-', linewidth=1)\n",
    "axs[1, 1].set_ylim(0, 1)  \n",
    "axs[1, 1].set_xlabel('Models')\n",
    "axs[1, 1].set_xticks(r , models, rotation=300, ha='left', va='top')\n",
    "axs[1, 1].set_ylabel('MSE')\n",
    "axs[1, 1].set_title('Comparison of MSE Scores for Different Models')\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c171ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of accuracy scores\n",
    "accuracy_scores = np.array([accuracy_RNN, accuracy_RNN_tu, accuracy_SVM, accuracy_BoW, accuracy_BERT])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Set the width of each bar\n",
    "bar_width = 0.4\n",
    "\n",
    "# Set the position of each bar on the x-axis\n",
    "r = np.arange(len(models))\n",
    "\n",
    "# Initialize the bottom position of the bars\n",
    "bottom = np.zeros(len(models))\n",
    "\n",
    "# Plot the accuracy scores with blue color below the red line\n",
    "plt.bar(r, np.where(accuracy_scores > accuracy_scores[-1], accuracy_scores - accuracy_scores[-1], 0),\n",
    "    bottom=accuracy_scores[-1], color='lightblue', width=bar_width)\n",
    "\n",
    "# Plot the accuracy scores with light blue color above the red line\n",
    "plt.bar(r, accuracy_scores, bottom=bottom, color='b', width=bar_width)\n",
    "\n",
    "plt.bar(r[-1], accuracy_scores[-1], color='orange', width=bar_width)  # BERT plot in orange\n",
    "\n",
    "# Draw a line at the top of the BERT bar\n",
    "plt.axhline(y=accuracy_scores[-1], color='red', linestyle='-', linewidth=1)\n",
    "\n",
    "# Set the y-axis limits to focus on the desired region\n",
    "plt.ylim(0.8, 0.9)  # Adjust the limits\n",
    "\n",
    "# Plot the accuracy scores with light blue color above the red line\n",
    "plt.bar(r, np.where(accuracy_scores > accuracy_scores[-1], \n",
    "                    accuracy_scores - accuracy_scores[-1], 0), \n",
    "        bottom=accuracy_scores[-1],\n",
    "        color='lightblue', width=bar_width)\n",
    "\n",
    "# Add x-axis ticks and labels\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(r , models, rotation=300, ha='left', va='top')\n",
    "plt.title('Comparison of Accuracy Scores for Different Models')\n",
    "\n",
    "# Add legend\n",
    "below = mpatches.Patch(color='b', label='Below Baseline Model')\n",
    "above = mpatches.Patch(color='lightblue', label='Above Baseline Model')\n",
    "base = mpatches.Patch(color='orange', label='Baseline Model(BERT)')\n",
    "plt.legend(handles=[below, above,base])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501320bf",
   "metadata": {},
   "source": [
    "<h3 id=\"3.2\">3.2 Project Evaluation and Summary</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7822f2ec",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
